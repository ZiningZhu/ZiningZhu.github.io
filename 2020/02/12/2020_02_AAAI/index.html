<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>AAAI2020 | Zining&#39;s Space</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="This is a compiled notes during AAAI 2020. I mainly went to the sessions related to my research field, and several relevant fields:      NLP and neural network, machine learning   Explainable AI   AI">
<meta property="og:type" content="article">
<meta property="og:title" content="AAAI2020">
<meta property="og:url" content="http://ziningzhu.me/2020/02/12/2020_02_AAAI/index.html">
<meta property="og:site_name" content="Zining&#39;s Space">
<meta property="og:description" content="This is a compiled notes during AAAI 2020. I mainly went to the sessions related to my research field, and several relevant fields:      NLP and neural network, machine learning   Explainable AI   AI">
<meta property="og:locale">
<meta property="article:published_time" content="2020-02-12T14:10:00.000Z">
<meta property="article:modified_time" content="2021-02-23T22:19:54.641Z">
<meta property="article:author" content="Zining Zhu">
<meta property="article:tag" content="conferences">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@https:&#x2F;&#x2F;twitter.com&#x2F;zhuzining">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-84222809-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  <meta name="google-site-verification" content="DI7qg6_y3mwWTdMA-GjrIY60uIS0beb12GxXZZ4A6gw" />

  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  <script src="https://use.fontawesome.com/93f0a51ca6.js"></script>
<meta name="generator" content="Hexo 5.4.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Zining&#39;s Space</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a id="nav-twitter-link" class="nav-icon" target="_blank" rel="noopener" href="https://twitter.com/zhuzining">
        
        
          <a id="nav-linkedin-link" class="nav-icon" target="_blank" rel="noopener" href="https://www.linkedin.com/in/zining-zhu-49164496/">
        
        
          <a id="nav-github-link" class="nav-icon" target="_blank" rel="noopener" href="http://github.com/ZiningZhu">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://ziningzhu.me"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2020_02_AAAI" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/12/2020_02_AAAI/" class="article-date">
  <time datetime="2020-02-12T14:10:00.000Z" itemprop="datePublished">2020-02-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Academia/">Academia</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      AAAI2020
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>This is a compiled notes during AAAI 2020. I mainly went to the sessions related to my research field, and several relevant fields:    </p>
<ul>
<li>NLP and neural network, machine learning  </li>
<li>Explainable AI  </li>
<li>AI applied to societies  </li>
</ul>
<span id="more"></span>
<h1 id="Friday-0207"><a href="#Friday-0207" class="headerlink" title="Friday 0207"></a>Friday 0207</h1><h2 id="Tutorial-FA1-AI-in-Precision-Medicine"><a href="#Tutorial-FA1-AI-in-Precision-Medicine" class="headerlink" title="Tutorial FA1: AI in Precision Medicine"></a>Tutorial FA1: AI in Precision Medicine</h2><ul>
<li>Instead of interpreting models in a black-box manner, we should build explainable models in medication.</li>
</ul>
<h2 id="Tutorial-XAI"><a href="#Tutorial-XAI" class="headerlink" title="Tutorial XAI"></a>Tutorial XAI</h2><p>Their slides are at the website <a target="_blank" rel="noopener" href="https://xaitutorial2020.github.io/">xaitutorial2020.github.io</a></p>
<h2 id="Workshop-PPAI"><a href="#Workshop-PPAI" class="headerlink" title="Workshop PPAI"></a>Workshop PPAI</h2><p><a target="_blank" rel="noopener" href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/papers/paper_25.pdf">Privately computing influence in regression models</a></p>
<ul>
<li>Compute an influence score that encourages participants to give higher quality data points.</li>
<li>The influence score is not computable: approximate it.</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/papers/paper_29.pdf">Private learning for high dimensional targets with PATE</a></p>
<ul>
<li>PATE is for classification. How about image segmentation?</li>
<li>Approach: PCA to lower dimensions, then you can do PATE.</li>
<li>Details: Need to empirically determine the dimension for PCA. Also, need to bound the activations. Used an activation function that projects the logits onto unit ball.</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/papers/paper_27.pdf">Plans that remain private, even in hindsight</a></p>
<ul>
<li>Want to protect robot information from the maintainer (adversary).</li>
<li>Problem formulation: described a hierarchy of the maintainer’s knowledge (weakest: know nothing; highest: know the exact plan)</li>
<li>Method:<ul>
<li>Use bipartite graph (world state -&gt; plan state) to represent the problems.</li>
<li>Use rule-based methods (formal systems) to protect information.</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/papers/paper_9.pdf">A survey of differentially private GANs</a></p>
<p><a target="_blank" rel="noopener" href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/papers/paper_12.pdf">Scalable and provably accurate algorithms for differentially private, distributed decision tree learning</a> </p>
<ul>
<li>Decision Tree has a proof that the accuracy in each split operation does not become worse. Try to give a similar guarantee for differential privacy.</li>
<li>Also gave a comparison of three approaches empirically.<ul>
<li>NoisyCounts</li>
<li>LocalRNM</li>
</ul>
</li>
</ul>
<h2 id="Tutorial-FP1-Differential-Deep-Learning-on-Graphs"><a href="#Tutorial-FP1-Differential-Deep-Learning-on-Graphs" class="headerlink" title="Tutorial FP1: Differential Deep Learning on Graphs"></a>Tutorial FP1: Differential Deep Learning on Graphs</h2><p>Chengxi Zang. <a target="_blank" rel="noopener" href="http://www.calvinzang.com/DDLG_AAAI_2020.html">Tutorial website</a></p>
<p><strong>1. Introduction: differential deep learning and their graph applications</strong></p>
<p>Graph applications example:</p>
<ul>
<li>Network dynamics of social media. </li>
<li>Traffic data.</li>
</ul>
<p>Examples of DNN and differential equations:</p>
<ul>
<li><p>Residual Net -&gt; Differential equations -&gt; Neureal ODE</p>
</li>
<li><p>RNN -&gt; Residual RNN -&gt; differential equation RNN</p>
</li>
</ul>
<p>Example of normalizing flow -&gt; diff equations</p>
<ul>
<li>A normalizing flow is an invertible generative model.</li>
<li>P(X) -&gt; P(Z): inference. P(Z)-&gt;P(X): generation</li>
<li>Flow -&gt; residual flow -&gt; differential equation flow.</li>
</ul>
<p>NICE (neural invertible flow) </p>
<ul>
<li>NICE comes from Hamiltonian Systems</li>
<li>NICE vs RealNVP</li>
<li>NICE vs differential equations.</li>
</ul>
<p>Then we could do the other way. Converting diff equations into DNNs by numerical methods.</p>
<p><strong>2. Molecular graph generation in drug discovery</strong> </p>
<p> Encoding graph is hard. Decoding graph is much harder. (e.g., chemical constraints).</p>
<p><strong>3.Learning dynamics on graphs</strong></p>
<p>Goal: to predict temporal change or final states of complex systems</p>
<ul>
<li>Use differential equations (parameterized by neural networks) to model the system dynamics.</li>
</ul>
<p>Three tasks:</p>
<ul>
<li>Continuous-time dynamics prediction</li>
<li>Structured sequence prediction</li>
<li>Node classification / regression</li>
</ul>
<p>Propose to use NDCN (neural dynamics on complex networks) as a unified framework to solve all three of them.</p>
<p><strong>4. Mechanism discovery in graphs</strong></p>
<p>Goal: to find dynamical laws of complex systems</p>
<p><strong>5. Conclusion: discussions and Future Directions</strong> </p>
<h1 id="Saturday-0208"><a href="#Saturday-0208" class="headerlink" title="Saturday 0208"></a>Saturday 0208</h1><h2 id="W11S-Evaluating-Evaluation-of-AI-systems"><a href="#W11S-Evaluating-Evaluation-of-AI-systems" class="headerlink" title="W11S: Evaluating Evaluation of AI systems"></a>W11S: Evaluating Evaluation of AI systems</h2><p><a target="_blank" rel="noopener" href="http://eval.how/aaai-2020/program.html">The eval.how website with all links to their papers</a> </p>
<p>930-1030 Anna Rogers: The questions that the current AI can’t answer</p>
<ul>
<li>Models could still give good performances when inputting random embeddings.</li>
<li>BERT etc., model performances drop when we paraphrase.</li>
<li>Human evaluation results largely depend on the questions.</li>
</ul>
<p>11-12 Paper session 1</p>
<p>Jose Hernandez-Orallo: <a target="_blank" rel="noopener" href="http://eval.how/aaai-2020/REAIS19_p14.pdf">AI Evaluation: On Broken Yardsticks and measurement scales</a></p>
<ul>
<li><p>AI measurement suffers from a moving-target phenomenon.</p>
<ul>
<li>A “challenge-solve-and-replace” dynamics of AI benchmarks.</li>
</ul>
</li>
<li><p>The moving target: five possible causes</p>
<ul>
<li>AI effect: whenever something is automated, it is not intelligence any more</li>
<li>Superhuman abyss: What does it mean by saying “it goes beyond human performance”? There are many unfair extensions.</li>
<li>Resource neglect: breakthroughs are obtained with huge resources in terms of data, compute, supervision and other</li>
<li>Specialisation drift. Tendency of AI researchs to specialise to a particular task, or to overfit to a benchmark</li>
<li>Cognitive judge problem: manual or automatic cognitive effort is needed to produce and verify instances, frequently relying on human labellers or crowdsourcing.</li>
</ul>
</li>
<li>How to improve the evaluation metrics? Divide tasks into different categories:<ul>
<li>Ceiling. Ground truth is human intelligence. E.g., Turing Test, human voice generation.</li>
<li>Projectional. Once AI reaches human performance, the projected score is meaningful.</li>
<li>Transitional. Add dimensions once human performance is reached. E.g., Add noise to ImageNet.</li>
<li>Universal extrapolation. E.g., Predict brain tumor 5 years before.</li>
</ul>
</li>
<li>For each task, the measurement metrics (Table 1).</li>
<li>Could also measure from multiple dimensions.</li>
</ul>
<p>Christopher Pereyda and Lawrence Holder: <a target="_blank" rel="noopener" href="http://eval.how/aaai-2020/REAIS19_p8.pdf">Measuring the relative similarity and difficulty between AI benchmark problems</a></p>
<ul>
<li>A similarity framework to describe task similarity.</li>
<li>Evaluate this framework, by DNN performances on foundational datasets (Classification: MNIST, Fashion-MNIST, C10, C100, CP. RL environments: misc.).</li>
</ul>
<p>Azamat Kamzin, Prajwal Paudyal, Ayan Banerjee and Sandeep K.S.Gupta: <a target="_blank" rel="noopener" href="http://eval.how/aaai-2020/REAIS19_p13.pdf">Evaluating the gap between hype and performance of AI systems</a></p>
<ul>
<li><p>First look at the task, and then some up with evaluation metrics.</p>
</li>
<li><p>Five best practices for evaluating AI systems that can potentially address and explain the gap between hype and practically observed performance of AI systems.</p>
<ul>
<li>BP1: Transparency on the effects of evaluation methodologies on participant bias</li>
<li>BP2: Disclosure of priorities of evaluation criteria</li>
<li>BP3: Choosing robust metrics</li>
<li>BP4: Evaluation in terms of explainable concepts</li>
<li>BP5: Iterative evaluation on adaptive human AI interaction</li>
</ul>
</li>
</ul>
<p>Chris Welty, Praveen Paritosh, Lora Aroyo: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.01875">Metrology for AI: From benchmarks to instruments</a></p>
<ul>
<li>Would you use a yardstick to measure the thickness of a piece of paper?</li>
<li>35% of empirical paper authors don’t believe error bars to be important.</li>
<li>Learn from the metrology community.<ul>
<li>Reproducibility is very important. Reproducibility -&gt; Repeatability.</li>
</ul>
</li>
</ul>
<p>12-13 Odd Erik Gunderson: How can we know it is shoulders we stand on? Reproducibility and evaluation</p>
<p>14-1430 Paper session 2</p>
<p>Botty Dimanov, Umang Bhatt, Mateja Jamnik and Adrian Weller: <a target="_blank" rel="noopener" href="http://eval.how/aaai-2020/REAIS19_p7.pdf">You shouldn’t Trust Me: Learning models which conceal unfiarness from multiple explanation methods</a></p>
<ul>
<li>Message: feature importance contain little information about model fairness</li>
<li>Motivating example: while the importance of features are unchanged, a modified model could give maximal violation of demographic parity.</li>
<li>Propose a method to modify the classifiers..</li>
</ul>
<p>Deborah Raji and Genevieve Fried: <a target="_blank" rel="noopener" href="http://eval.how/aaai-2020/REAIS19_p12.pdf">About Face: Tracking shifting trends of facial recognition evaluation</a></p>
<ul>
<li><p>Facial recognition + fairness</p>
</li>
<li><p>Different era has different data source + technology + demographic information</p>
</li>
</ul>
<p>1430-1530 Sam Henry. Amazon Augmented AI: People + AI = Magic</p>
<ul>
<li>Background<ul>
<li>Humans continuously review for ML auditoring</li>
<li>Combining humans and ML is hard</li>
</ul>
</li>
<li>Product: Amazon Augmented AI (A2I)<ul>
<li>Easily implement human review of machine learning predictions</li>
</ul>
</li>
<li>BTW: $4000 funding for collecting datasets.</li>
</ul>
<p>1600-1645 Paper Session 3</p>
<p>Stefano Alletto, Shenyang Huang, Vincent Francois-Lavet, Yohei Nakata and Guillaume Rabusseau: RandomNet: Towards fully automatic neural architecture design for multimodal learning</p>
<p>Julian Niedermeier, Goncalo Mordido and Christoph Meinel: Improving the evaluation of generative models with fuzzy logic</p>
<p>Huiyuan Xie, Tom Sherborne, Alexander Kuhnie and Ann Copestake: Going beneath the surface: Evaluating image captioning for grammaticality, trustfulness, and diversity</p>
<p>1645-1730: Panel: perspectives on self-evaluation. Should researchers, goups, companies evaluate their own work, or is a more adversarial approach necessary to achieve evaluation quality?</p>
<h1 id="Sunday-0209"><a href="#Sunday-0209" class="headerlink" title="Sunday 0209"></a>Sunday 0209</h1><h2 id="Document-Analysis-and-Understanding"><a href="#Document-Analysis-and-Understanding" class="headerlink" title="Document Analysis and Understanding"></a>Document Analysis and Understanding</h2><p>Liao et al. <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-LiaoM.578.pdf">Real-time scene text detection with differentiable binarization</a></p>
<ul>
<li>Task: read text in scene images (scene text detection)</li>
<li>Approach: Differentiable Binarization. Compute segmentation map and threshold map, then convert to binarization map to get detection results.</li>
<li>Experiment on five benchmark datasets of scene text. </li>
<li>Also compared speed of experiments.</li>
</ul>
<p>Qiao et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-QiaoL.893.pdf">Text perception: towards end-to-end arbitrary-shaped text spotting</a></p>
<ul>
<li><p>Task: scene text detection.</p>
</li>
<li><p>Proposed a Shape Transformation Module</p>
</li>
</ul>
<p>Hu et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-HuW.7838.pdf">GTC: Guided Training of CTC towards efficient and accurate scene text recognition</a></p>
<ul>
<li>Scene text detection</li>
<li>Approach:<ul>
<li>Guided training: GCN+CTC Decoder</li>
<li>Inference: Only keep the GCN stream.</li>
</ul>
</li>
</ul>
<h2 id="Interpretable-AI"><a href="#Interpretable-AI" class="headerlink" title="Interpretable AI"></a>Interpretable AI</h2><p>Delleiger and Vreeken, <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-DalleigerS.8171.pdf">Explainable Data Decompositions</a></p>
<ul>
<li><p>Define the <em>pattern composition</em> problem with a regularized max likelihood.</p>
<ul>
<li><script type="math/tex; mode=display">
l(\pi, S, A) = -\Sigma_{D_j} log p(D_j | S_j) + r(\pi, S, A)</script></li>
<li><p>D is a set of data points. S is the set of patterns.</p>
</li>
</ul>
</li>
<li><p>Fast method for discovering pattern components &amp; compositions.</p>
</li>
</ul>
<p>Zhang, <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-ZhangL.1830.pdf">Systematically Exploring Associations among multivariate data</a></p>
<ul>
<li>Propose the nCor: neighbor correlation coefficient</li>
<li>Measure the local continuity of the reordered data points to quantify the strength of the global association between variables.</li>
</ul>
<p>Qi et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-QiZ.4029.pdf">Visualizing deep networks by optimizing with integrated gradients</a></p>
<ul>
<li>Propose I-GOS: optimizes for a heatmap, so that the classification scores on the masked image would maximally decrease.</li>
<li>Train on integrated gradients instead of individual gradients, so it’s less likely to get trapped in local minima.</li>
</ul>
<p>Zhong et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-ZhongH.7101.pdf">Iteratively questioning and answering for interpretable legal judgment prediction</a></p>
<ul>
<li>Network design:<ul>
<li>Question Net: select questions from a given set</li>
<li>Answer Net: answer the question according to the fact description.</li>
<li>Predict Net: produce judgment results based on the answers.</li>
</ul>
</li>
<li>Design reward functions to minimize the n. questions asked.</li>
</ul>
<p>Tomsett et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-TomsettR.8794.pdf">Sanity checks for saliency metrics</a></p>
<ul>
<li>Investigate the properties of different approaches for measuring the fidelity of saliency map explanations for image classifiers.</li>
<li>Propose a corresponding set of sanity checks for saliency metrics based on measures of reliability from psychometric testing literature.</li>
<li>Psychometric test reliability is usually estimated in four separate ways (Peter 1979). Neural network as the agent, saliency methods as a battery of psychometric tests.<ul>
<li>Inter-rater reliability: For each image, check the agreement of saliency metric scores.</li>
<li>Inter-method reliability: Assesses the degree to which test scores are consistent when there is a variation in the methods / instruments used.</li>
<li>Internal consistency reliability: Degree to which different methods intending to measure the same concept produce similar scores.</li>
<li>Test-retest reliability. (not relevant for saliency methods)</li>
</ul>
</li>
</ul>
<p>Virani et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-ViraniN.9085.pdf">Justification-based reliability in ML</a></p>
<ul>
<li>Extend the Justified True Belief in epistemology, to characterizing the validity and limits of knowledge in supervised classifiers.</li>
<li>An epistemic classifier characterizes the region where it is confident and not. The goal is to train an epistemic classifier.<ul>
<li>JTB theory: knowledge = “justified + true” belief.</li>
<li>“justified”: gathers evidence using the training set for each individual test input x in the layers of NN classifier, where:<ul>
<li>an unambiguous truth state in the neighborhood of x in embedded spaces provide support to the belief </li>
</ul>
</li>
<li>allowing the model to declare “I know it”, “I might know”, or “I don’t know” (output classification results from either “IK”, “IMK” or “IDK”).</li>
</ul>
</li>
</ul>
<h2 id="NLP-session"><a href="#NLP-session" class="headerlink" title="NLP session"></a>NLP session</h2><p>Jin et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-JinD.7014.pdf">Is BERT really robust? A strong baseline for natural language attack on text classification and entailment</a></p>
<ul>
<li>Adversarial perturbation approach:<ul>
<li>Identify the important words</li>
<li>Change the words to the most semantically similar and grammatically correct words until the prediction is altered.</li>
</ul>
</li>
</ul>
<p>Sahin and Gurevych, <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-SahinG.7400.pdf">Investigating invertible NNs for inverse problems in morphology</a> </p>
<ul>
<li>Task: morphological inflection and lemmatization</li>
<li>Use Invertible Neural Networks to optimize both direction problems simultaneously</li>
</ul>
<p>Aguilar et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-AguilarG.8219.pdf">Knowledge Distillation from internal representations</a> </p>
<ul>
<li>Distill the BERT representations into a simplified BERT version (with less layers).</li>
</ul>
<h2 id="ML-Neural-Nets-etc"><a href="#ML-Neural-Nets-etc" class="headerlink" title="ML: Neural Nets etc."></a>ML: Neural Nets etc.</h2><p>Tian et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-TianK.8084.pdf">Network as regularization for training DNN</a> </p>
<ul>
<li>Propose Network as Regularization (NaR) - use an auxiliary network to dynamically incorporate guided semantic disturbance to the labels.</li>
<li>Target-based regularization: instead of focusing on the primary class, the model also pays some attention to the other classes. Many existing regularization methods adopt prior knowledge as reg term in loss function.</li>
<li>How is the auxiliary network trained? ground-truth label y, independently.</li>
<li>Convex comb the two network’s outputs as noise, then add this noise to label of training the target network.</li>
<li>Good results on some datasets in comparison to baselines. </li>
</ul>
<h2 id="ML-Causal-Learning-and-Bayes-Nets"><a href="#ML-Causal-Learning-and-Bayes-Nets" class="headerlink" title="ML: Causal Learning and Bayes Nets"></a>ML: Causal Learning and Bayes Nets</h2><p>Faury et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-FauryL.3429.pdf">Distributionally robust counterfactual risk minimization</a></p>
<ul>
<li>A unified framework for counterfactual risk minimization based on the DRO (distribuionally robust optimization) of policies.</li>
</ul>
<p>Schwab et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-SchwabP.4296.pdf">Learning counterfactual Representations for Estimating Individual Dose-Response Curves</a></p>
<ul>
<li>Dose Response Network (DRNet) architecture. Lower layers are shared, but higher layers branch into different heads.  Assign heads corresponding to the dosage strata.</li>
</ul>
<p>Dhir and Lee, <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-DhirA.5855.pdf">Integrating Overlapping Datasets using Bivariate Causal Discovery</a></p>
<ul>
<li>Problem setting (motivating example). E.g., Dataset (X,Y) and (Y,Z) are separately collected. We know X-&gt;Y, and Y&lt;-&gt;Z. Want to find if there are common causes between X and Z. But these two datasets are not measured at the same conditions. Need some <em>bivariate causal discovery</em> methods.</li>
<li>Propose approach that outperform previous bivariate causal discovery algorithms.</li>
</ul>
<p>Yu et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-YuM.6025.pdf">A new framework for online testing of heterogeneous treatment effect</a></p>
<ul>
<li>Propose Sequential Score Test (SST)<ul>
<li>Can control type I error under continuous monitoring and detect multi-dimensional heterogeneous treatment effects.</li>
</ul>
</li>
<li>Compare to SOTA online test (mSPRT).</li>
</ul>
<h2 id="ML-Fairness-and-Privacy-Learning-Theory"><a href="#ML-Fairness-and-Privacy-Learning-Theory" class="headerlink" title="ML: Fairness and Privacy, Learning Theory"></a>ML: Fairness and Privacy, Learning Theory</h2><p>Davidson and Ravi., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-DavidsonI.5319.pdf">Making existing clusterings fairer: algos, complexity results, and insights</a></p>
<ul>
<li>Formulate the minimal cluster modification for fairness (MCMF) problem.<ul>
<li>Input: a given partitional clustering</li>
<li>Goal: minimally change it, so that the clustering is still of good quality and fairer.</li>
</ul>
</li>
</ul>
<p>Dutta et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-DuttaS.9451.pdf">An info-theoretic quantification of discrimination with Exempt Features</a></p>
<ul>
<li>Goal: define non-exempt discrimination, while exempting discrimination due to critical features.</li>
<li>Tool: partial information decomposition (PID) from information theory<ul>
<li>Counterfactual causal influence &amp; counterfactual fairness</li>
</ul>
</li>
<li>Decomposition of total discrimination into four non-negative components (exempt and non-exempt visible discrimination, exempt and non-exempt masked discrimination)</li>
<li>An impossibility result (no purely observational measure of non-exempt discrimination can satisfy all our desirable properties)</li>
<li>Observational relaxations</li>
</ul>
<p>Harder et al., <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-HarderF.3435.pdf">Interpretable and differentially private predictions</a></p>
<ul>
<li>Trade-off between interpretability, privacy, and accuracy.</li>
<li>Propose a family of interpretable models (“LLM, locally linear maps”), accounting privacy and interpretability.</li>
<li>Provide DP “local” and “global” explanations on classification.</li>
<li>Use random projections (Johnson-Lindenstrauss transform) to better deal with privacy and accuracy trade-off.</li>
</ul>
<p>Wang and Zhou, <a target="_blank" rel="noopener" href="http://aaai.org/Papers/AAAI/2020GB/AAAI-WangJ.9491.pdf">Differentially private learning with small public data</a></p>
<ul>
<li>Private-public stochastic gradient descent.</li>
<li>Use public database to adjust privacy budget &amp; gradient clipping of SGD training of private training database. Also use public database to fine-tune the model.</li>
</ul>
<h1 id="Monday-0210"><a href="#Monday-0210" class="headerlink" title="Monday 0210"></a>Monday 0210</h1><h2 id="Games-Description-Languages-and-NLP"><a href="#Games-Description-Languages-and-NLP" class="headerlink" title="Games: Description Languages and NLP"></a>Games: Description Languages and NLP</h2><p>(Madison, 930-1045)</p>
<p>Goldwaser and Thielscher, <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-GoldwaserA.4814.pdf">Deep RL for general game playing</a> </p>
<ul>
<li>General Game Playing: providing game rules only at runtime. Agents are allowed some starttime to analyze the game strategies.</li>
<li>Game Description Language (GDL) logical programming<ul>
<li>Previous approaches: Construct propositional networks</li>
</ul>
</li>
<li>Proposed approach: GCP with reinforcement learning</li>
<li>Limitations for AlphaZero: Needs a handcrafted neural network, zero sum, turn-based, two-player, play-specific. How to remove these limitations?<ul>
<li>GDL input -&gt; Propositional network-&gt;DNN-&gt;RL, computing expected reward for move probabilities of multiple players’ outputs.</li>
<li>The DNN is shared (for common feature extraction)</li>
<li>Each player has their own move space. Move simultaneously.</li>
<li>Automatically generated NN</li>
<li>Expected reward allows cooperative strategies.</li>
</ul>
</li>
<li>Evaluation method:<ul>
<li>Compared to UCT: run both with equal time per move, and run with equal number of simulations</li>
</ul>
</li>
</ul>
<p>Hayton et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-HaytonT.6762.pdf">Narrative Planning Model Acquisition from Text summaries and descriptions</a></p>
<ul>
<li>Background: baseline narrative planning.</li>
<li>Aim of this work: approach to assist authors / reduce authoring burden via a semi-automated route to baseline narrative planning model development.</li>
<li>Planning model acquisition from text summaries<ul>
<li>From input natural language sentences to baseline domain model</li>
<li>Segmentation -&gt; Object identification -&gt; Reference co-resolution -&gt; Narrative domain model acquisition (target PDDL representation)</li>
<li>Domain model acquisition: the output is a PDDL model (Planning domain definition language. McDermott et al., 1998)</li>
</ul>
</li>
</ul>
<p>Hausknecht et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-HausknechtM.9405.pdf">Interactive Fiction Games: A Colossal Adventure</a> </p>
<ul>
<li>Interactive Fiction games are fully text-based simulation environments where a player issues text commands to effect change in the environment and progress through the story.</li>
<li>Challenges IF games provide for agents:<ul>
<li>Combinational Action Space</li>
<li>Commonsense Reasoning</li>
<li>Knowledge Representation</li>
</ul>
</li>
<li>Introduce Jericho: learning environment for 56 man-made IF games across the spectrum of difficulty.<ul>
<li>Reward / game over / victory detection</li>
<li>Save / load game states</li>
<li>Walkthroughs, vocabulary identification, action templates, valid action detection…</li>
</ul>
</li>
</ul>
<p>Shi et al,. <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ShiT.147.pdf">Fast and Robust Face-to-Parameter Translation for Game character auto-creation</a> </p>
<ul>
<li>Formulate a “game character auto-creation” framework”: predict a large set of physically meaningful facial parameters under a self-supervised learning paradigm, according to the input face photo.</li>
<li>Previous methods: <ul>
<li>3D reconstruction (morphable face models of 3D reconstructions vs. bone-driven face models in RPG games)</li>
<li>F2P (face to parameters): iteratively adjust params at the input end of the renderer by gradient descent. Slow.</li>
</ul>
</li>
<li>Propose network:<ul>
<li>Translator T and Imitator G. Optimize using a cycle-consistency loss.</li>
<li>Also has segmentation networks, etc. See orig paper for their pipeline.</li>
</ul>
</li>
<li>Evaluation:<ul>
<li>Two games: Justice and Revelation.</li>
<li>Subjective evaluation from 15 volunteers.</li>
<li>Ablation studies on several loss components.</li>
</ul>
</li>
</ul>
<p>Liu et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuD. 6731.pdf">A Character-centric neural model for automated story generation</a> </p>
<ul>
<li>Task: Automated story generation.</li>
<li>Previous models (VAE, GAN, Conv-Seq2Seq) models didn’t incorporate attributes and prior knowledge of the story genre.</li>
<li>Proposed method: combine deep generation networks with character modeling (allocate a consistent character to a story, via encoding it into the distributed embedding)</li>
<li>Decompose the story generation into two steps:<ul>
<li>First, determine the character’s reaction to the current situation at each time step</li>
<li>Second, generate a complete sentence by incorporating the character embedding, predicted action, and the situation information.</li>
</ul>
</li>
<li>Experiment:<ul>
<li>Dataset: corpus of movie plot summaries extracted from Wikipedia</li>
<li>Baseline models: Conditional LM, S2S with attention, incremental S2S with attention, plan-and-write, event representation, hierarchical convolution sequence model.</li>
<li>Evaluation metrics: BLEU, Perplexity, Human Evaluation.</li>
</ul>
</li>
</ul>
<p>Fan et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-FanA.7370.pdf">Generating Interactive Worlds with Text</a> </p>
<ul>
<li>Task: generate cohesive and interesting game environments.</li>
<li>Investigate a ML approach for world creating, using the LIGHT game environment.</li>
<li>Use NN-based models to compositionally arrange locations, characters, and objects into a coherent whole.</li>
</ul>
<p>Yu et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-YuM.8133.pdf">Draft and Edit: Automatic storytelling through multi-pass hierarchical conditional VAE</a> </p>
<ul>
<li>Main challenge of story generation: <ul>
<li>Consistency<ul>
<li>Current SOTA solution: exploit intermediate representations (keywords, events, skeleton) to provide better guidance for the story generation process. Risky + Complex</li>
</ul>
</li>
<li>Diversity<ul>
<li>VAE with noise (also has drawbacks and randomness)</li>
</ul>
</li>
</ul>
</li>
<li>Propose model<ul>
<li>Consistency: use hierarchical structure</li>
<li>Diversity: CVAE model + Multi-pass generation.</li>
</ul>
</li>
</ul>
<h2 id="Application-Human-Modeling"><a href="#Application-Human-Modeling" class="headerlink" title="Application: Human Modeling"></a>Application: Human Modeling</h2><p>(Beekman, 1115-1230)</p>
<p>Zhang et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhangT.2962.pdf">Variational Pathway Reasoning for EEG emotion recognition</a> </p>
<ul>
<li>Introduced Variational Pathway Reasoning (VPR) method to EEG emotion recognition.</li>
<li>A salient pathway reasoning method is proposed:<ul>
<li>EEG -&gt; {Random walk -&gt; pathway candidates -&gt; Sequence modeling -&gt; Pathway codes} (pathway sampling and coding) -&gt; Salient pathway reasoning</li>
<li>How to do salient pathway reasoning? Sparse variation scaling, pseudo salient pathways, etc…. -&gt; Full conv layer</li>
</ul>
</li>
<li>Experiments:<ul>
<li>Accuracy vs benchmarks</li>
<li>Visualization of salient pathways.</li>
</ul>
</li>
</ul>
<p>Mittal et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-MittalT.4411.pdf">M3ER: Multiplicative MultiModal Emotion recognition using facial, textual, and speech cues</a> </p>
<ul>
<li>Task: emotion perception<ul>
<li>Input: image, speech, etc. Output: perceived emotion.</li>
</ul>
</li>
<li>Previous approaches:<ul>
<li>Unimodal emotion recognition. Either of facial, speech, body gestures, or physiological features.</li>
<li>Multimodal emotion recognition. Early fusion, dynamic fusion graphs, tensor fusion networks, etc.</li>
</ul>
</li>
<li>Approach: M3ER<ul>
<li>Modality check step with CCA. Discard some ineffective modalities with some heuristics.</li>
<li>Proxy feature generator. Generate proxy feature vectors for the ineffectual modalities using a linear transformation.</li>
<li>Multiplicative combination step.</li>
</ul>
</li>
<li>Dataset:<ul>
<li>IEMOCAP Dataset (Busso et al., 2008). 3 modalities of 10 actors.</li>
<li>CMU MOSEI dataset (Zadeh et al., 2018)</li>
</ul>
</li>
</ul>
<p>Zhao et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhaoS.7155.pdf">An end-to-end visual-audio attention network for emotion recognition in user-generated videos</a> </p>
<ul>
<li>Challenges in emotion recognition:<ul>
<li>Large intra-class ariation: affective gap</li>
<li>Low structured consistency: resolutions and bulrring noises</li>
<li>Sparse keyframe expression. Only limited keyframes directly convey and determine emotions.</li>
</ul>
</li>
<li>Propose visual-audio attention network (VAANet), to study emotion recognition task in user-generated video in E2E manner.</li>
<li>Polarity-consistent cross entorpy loss (increase the penalty coefficient if the polarity of prediction is different from the ground truth label).</li>
</ul>
<p>Song et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-SongT.2747.pdf">Instance-Adaptive graph for EEG emotion recognition</a> </p>
<ul>
<li>Propose Instance-adaptive graph</li>
<li>(See Figure 2)  Use instance -adaptive branch to achieve the dynamic graphic connections.</li>
<li>Then process EEG by multi-level and multi-graph convolution, graph coarsening, region dependency modeling, then FC and softmax.</li>
</ul>
<p>Bhattacharya et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-BhattacharyaU.2895.pdf">STEP: Spatial Temporal Graph Convolutional Networks for emotion perception from gaits</a> </p>
<ul>
<li>Use real+generated data and gait-based effective features.</li>
<li>Generate with conditional VAE.</li>
<li>Use novel emotion-gait dataset.</li>
</ul>
<p>Perrault et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-PerraultA.5897.pdf">End-to-end game-focused learning of adversary behavior in security games</a> </p>
<ul>
<li>Problem: want to generalize from one security game to another against the same adversary<ul>
<li>Adversary has a fixed but unobserved attractiveness function</li>
<li>Goal: learn the attractiveness function to maximize defender utility.</li>
</ul>
</li>
<li>Using a predict then optimize approach may not maximize utility</li>
<li>This paper: learn a predictive model using a game-focused loss function<ul>
<li>Maximize a surrogate for decision quality.</li>
</ul>
</li>
<li>Result: better performance with less data.</li>
</ul>
<p>Yang et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-YangX.7952.pdf">Instance-wise dynamic sensor selection for human activity recognition</a></p>
<ul>
<li>Need more sensors to recognize human activies, but how to balance sensoe numbers and the cost?</li>
<li>Alternatively minimize classification loss and sensor number<ul>
<li>MDP-based sensor model, sensoe-adaptive activity model, Mutual DAgger imitation learning.</li>
</ul>
</li>
</ul>
<h2 id="ML-Unsupervised-and-Semi-supervised-Learning-clustering-2"><a href="#ML-Unsupervised-and-Semi-supervised-Learning-clustering-2" class="headerlink" title="ML Unsupervised and Semi-supervised Learning, clustering 2"></a>ML Unsupervised and Semi-supervised Learning, clustering 2</h2><p>Chen et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ChenM.5090.pdf">Multi-view clustering in latent embedding space</a> </p>
<ul>
<li>Background: global similarity learning</li>
<li>Learn a similarity matrix S, where s_ij is the similarity between sample i and j</li>
<li>Propose MCLES approach: optimize Eq (9).</li>
<li>Evaluate on ACC, NMI, and PUR against various baselines.</li>
</ul>
<h2 id="ML-Unsupervised-and-semi-supervised-learning-clustering-3"><a href="#ML-Unsupervised-and-semi-supervised-learning-clustering-3" class="headerlink" title="ML Unsupervised and semi-supervised learning, clustering 3"></a>ML Unsupervised and semi-supervised learning, clustering 3</h2><p>(Concourse A, 1400-1515)</p>
<p>Zhou et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhouS.4849.pdf">Multi-view spectral clustering with optimal neighborhood laplacian matrix</a> </p>
<ul>
<li>The current linear combination-based multi-view spectral clustering framework could: (1) limit the representation capacity of the learned Laplacian matrix, and (2) insufficiently explore the high-order neighborhood information among data</li>
<li>Provide a flexible optimal Laplacian matrix construction mechanism to solve the aforementioned issues.<ul>
<li>Seeds an optimal Laplacian matrix L* in the neighborhood of both the linear comb of first-order and high-order base Laplacian matrices.</li>
</ul>
</li>
<li>Experimental study on eight benchmark datasets.</li>
</ul>
<p>Sun et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-SunG.2320.pdf">Lifelong spectral clustering</a> </p>
<ul>
<li>Spectral clustering in lifelong learning setting</li>
<li>Two common knowledge libraries: orthogonal basis library B and feature embedding library F.</li>
</ul>
<p>Wang et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-WangB.4495.pdf">Robust self-weighted multi-view projection clustering</a> </p>
<ul>
<li>Propose RSwMPC. </li>
<li>Subspace learning is performed by adding a projection matrix. Feature selection and noise suppression are achieved by introducing the l_2,1-norm penalty term of the projection matrix.</li>
<li>Parameter-free self-weighted strategy.</li>
<li>Experiments on synthetic and real-world datasets.</li>
</ul>
<p>Ma et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-MaL.6294.pdf">Inefficiency of K-FAC for large batch size training</a></p>
<ul>
<li>Can second order method (K-FAC) improve the critical batch size problems? </li>
<li>K-FAC also significantly deviate from ideal strong scaling behaviour, when training beyond a critical batch size.</li>
<li>Experiments on CIFAR-10 and SVHN.</li>
</ul>
<p>Cheng et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ChengL.6641.pdf">Outlier detection ensemble with embedded feature selection</a> </p>
<ul>
<li>Motivation: outlier detection. feature selection. Usually these two steps are done separately or iteratively.</li>
<li>Solution: ODEFS: Integration of feature selection, outlier candidates selection, and outlier detection.</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-MiklautzL.7182.pdf">Deep Embedded Non-redundant clustering</a></p>
<ul>
<li>What is non-redundant clustering? </li>
<li>Deep clustering techniques cluster in the latent space.</li>
<li>Joint learn the class-specific clusters of representations in latent space using a non-redundant clustering layer.</li>
</ul>
<p>Li et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LiX.9315.pdf">IVFS: Simple adn efficient feature selection for high-dimensional topology preservation</a> </p>
<ul>
<li>IVFS is inspired by random subset method.</li>
<li>Proposed algorithm can provide satisfactory performance under a sharp sub-sampling rate.</li>
</ul>
<p>Guo et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-GuoJ.9616.pdf">Preserving ordinal consensus: towards feature selection for unlabeled data</a>  </p>
<ul>
<li>Motivation: <ul>
<li>exploit one-to-one correspondence</li>
<li>exploit feature-level ordinal information</li>
</ul>
</li>
<li>Method: self-paced joint learning model</li>
</ul>
<h2 id="ML-Domain-Adaptation-Learning"><a href="#ML-Domain-Adaptation-Learning" class="headerlink" title="ML Domain Adaptation, *-Learning."></a>ML Domain Adaptation, *-Learning.</h2><p>(Murray Hill, 1545-1715)</p>
<p>Lee et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LeeJ.4101.pdf">Residual Continual Learning</a> </p>
<ul>
<li>What is continual learning? Learn multiple tasks sequentially, without forgetting.</li>
<li>Linear combination of source network and target network, to form a combined network.</li>
</ul>
<p>Chandak et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ChandakY.6189.pdf">Lifelong Learning with a changing action set</a> </p>
<ul>
<li>(Outstanding student paper award, honorable mention)</li>
<li>Lifelong MDP setup:<ul>
<li>How do we capture the notion of underlying structure in action space?</li>
<li>How does the action set change?</li>
<li>What are the characteristic properties of a changing action set?</li>
</ul>
</li>
<li>Proposed solution:<ul>
<li>A policy parameterization that is invariant to the cardinality of the action set.</li>
<li>A new obj func which can be used to update the agent when new actions are introduced.</li>
</ul>
</li>
<li>Proposed method:<ul>
<li>What if we could infer the underlying structure in the action space and whenever a new action is introduced we associate its behavior using the inferred underlying structure?</li>
<li>Policy parameterization is critical.</li>
</ul>
</li>
</ul>
<p>Li et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LiY.443.pdf">Learning transferable adversarial examples via ghost networks</a> </p>
<ul>
<li>Longitudinally ensemble the ghost networks.</li>
<li>Dropout erosion; skip connection erosion</li>
<li>Evaluate on the NeurIPS 2017 adversarial challenge.</li>
</ul>
<p>Liu et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LiuL.1273.pdf">Attribute propagation network for graph zero-shot learning</a> </p>
<ul>
<li>Aim to optimize the attribute space in the context of ZSL, and leverage the inter-class relations to generate more powerful attribute vector per class.</li>
<li>APNet: propagate the attributes of every class on the category graph to its neighbors in order to generate attribute vectors.</li>
<li>Inspired by belief propagation, message passing and label propagation. Also related to GNN.</li>
</ul>
<p>Zhu and Li, <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhuY.4960.pdf">Semi-supervised streaming learning with emerging new labels</a> </p>
<ul>
<li>Problem: the data are collected in the stream. New class hides in unlabeled data.</li>
<li>Solution: semi-supervised learning framework “SEEN” method:<ul>
<li>Add the data point to a buffer, if it is likely belonging to a new class. (as determined by a detector)</li>
<li>How to add the data points from the buffer into corresponding category, if a new label is introduced?</li>
<li>SeenLP for known class classification, usign label propagation.</li>
</ul>
</li>
</ul>
<h1 id="Tuesday-0211"><a href="#Tuesday-0211" class="headerlink" title="Tuesday 0211"></a>Tuesday 0211</h1><h2 id="Fairness-and-Equality-in-Economic-Paradigms"><a href="#Fairness-and-Equality-in-Economic-Paradigms" class="headerlink" title="Fairness and Equality in Economic Paradigms"></a>Fairness and Equality in Economic Paradigms</h2><p>(930-1045, Bryant)</p>
<p>Patro et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-PatroG.5266.pdf">Incremental Fairness in Two-sided market platforms: on smoothly updating recommendations</a> </p>
<ul>
<li>Focus: personalized recommendations on two-sided platforms</li>
<li>Terminology:<ul>
<li>Exposure of producers</li>
<li>Relevance score</li>
<li>Utility of recommendation</li>
</ul>
</li>
<li>Tested types of recommendatoin updates<ul>
<li>Change in relevance scoring model (Amazon-M. Collaborative filtering)</li>
<li>Addition of new data (Amazon-D). Factorization model</li>
<li>Addition of new features (GoogleLoc-F. Google Maps / places recommendation)</li>
</ul>
</li>
<li>69-98% of producers face 100+% change in their exposure / visibility immediately due to the updates. Sudden change in exposure is undesirable.</li>
<li>An update is incrementally fair if the difference between the exposure distribution is smaller than epsilon. </li>
<li>Fairness guarantee: need to guarantee a min utility for customer.</li>
<li>Method: formulate into an integer programming problem.</li>
<li>Baseline methods:<ul>
<li>Canary deployment (phased roll out) (some customers will get less utility than others; unfair to customers.)</li>
<li>Intermediate Relevance Function (does not consider producer or customer)</li>
</ul>
</li>
</ul>
<p>Eiben et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-EibenE.5775.pdf">Parameterized complexity of envy-free resource allocation in social networks</a> </p>
<ul>
<li>Resource allocation of items. Some items are indivisible. So that no agent envies another one. <ul>
<li>(An agent envies another one if the other one has more value than itself)</li>
</ul>
</li>
<li>Envy-freeness in social networks:<ul>
<li>Mostly unreasonable to assume agents know complex assignment.</li>
<li>Local envy-freeness. Goal: allocate so that no agent directly envies another one.</li>
<li>Global envy-freeness: a stronger assumption.</li>
</ul>
</li>
<li>Envy-free allocation is hard:<ul>
<li>In a complete social network, allocating resources in a locally envy-free way is NP-hard.</li>
<li>For edgeless social network, doing it in envy-free way is also NP-hard</li>
</ul>
</li>
<li>Parameterized complexity theory:<ul>
<li>Instead of measuring asymptotic complexity in terms of instance size n, additionally consider a parameter k.</li>
</ul>
</li>
<li>Resource and agent types</li>
<li>Social network types</li>
<li>Results:<ul>
<li>On their own restricting social graph structure and n. of types  do not yield polynomial time solvability</li>
<li>Together restricting social graph structure and number of types yield polynomial time solvability</li>
<li>Future work: Parameterized complexity wrt the number of resource types for complete social networks?</li>
</ul>
</li>
</ul>
<p>Abebe et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-AbebeR.9353.pdf">Subsidy Allocations in the presence of income shocks</a> </p>
<ul>
<li>Background: poverty, income, shock</li>
<li>Min-max via binary search.</li>
<li>An optimal solution: min-sum objective, using knapsack.</li>
<li>There is a gap between our alg and the income subsidy method which only focuses on income.</li>
<li>How different are min-sum and min-max objectives? Entirely different solutions.</li>
<li>Income vs wealth subsidy?</li>
</ul>
<p>Tziavelis et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-TziavelisN.3062.pdf">Fair procedure for fair stable marriage outcomes</a> </p>
<ul>
<li>Problem setting: two-sided market where each agent ranks those on the other side by preference.</li>
<li>Stable marriage: find a perfect matching, such that no pair of agents prefer each other to their matches.</li>
<li>Gale-Shapley alg is not good enough (optimal match for one side, but pessimal one to the other side)</li>
<li>Gale-Shapley extension: two-sided proposals.<ul>
<li>Fair procedures that reach an equitable stable marriage in cubic time.</li>
</ul>
</li>
</ul>
<p>Lv et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LvH.3279.pdf">Mechanism design with predicted task revenue for bike sharing systems</a> </p>
<ul>
<li>Key idea: <ul>
<li>Sort users and tasks together.</li>
<li>Maintain asub-graph that always has a right-perfect matching</li>
</ul>
</li>
<li>Incentive compatible, budget feasible, individually rational, computationally efficient, 2-approximate.</li>
</ul>
<h2 id="Human-and-AI-3"><a href="#Human-and-AI-3" class="headerlink" title="Human and AI 3"></a>Human and AI 3</h2><p>(Clinton, 1115-1230)</p>
<p>Evertsz and Thangarajah, <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-EvertszR.923.pdf">A framework for engineering human/agent teaming system</a> </p>
<ul>
<li>How to engineer MAS (multi-agent system) to support human team members?</li>
<li>Identify key human/agent teaming parameters<ul>
<li>Foster team transparency</li>
</ul>
</li>
<li>Methodology for engineering human/agent teams<ul>
<li>What artefacts to represent</li>
<li>How to represent these artefacts</li>
</ul>
</li>
<li>TDF: Tactics development framework</li>
<li>Runtime</li>
</ul>
<p>Tang and Yang, <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-TangZ.1783.pdf">Corpus-level end-to-end exploration for interactive systems</a> </p>
<ul>
<li>Retrieval based interactive systems</li>
<li>Common pipeline:<ul>
<li>Environment + Action of RL agents.</li>
<li>Drawback: most existin gretrieval functions are optimized over precision at top ranks. -&gt; The RL agent do not have a global view of the problem.</li>
<li>Non-differentiability of retrieval functions.</li>
</ul>
</li>
<li>Dynamic Search:<ul>
<li>Background: Multi-turn information seeking</li>
</ul>
</li>
<li>Key idea:<ul>
<li>Maintain global-oriented task</li>
<li>The interactions with a human user.</li>
</ul>
</li>
<li>To represent segments:<ul>
<li>Option 1: Doc2vec (unable to handle the crowding problem: lower dimensional space may not be able to accommodate all the datapoints from higher dimensional space. Documents may collapse.)</li>
<li>Option 2: t-SNE. </li>
</ul>
</li>
<li>Differentiable retrieval function (so we can optimize a value network)</li>
<li>Train the policy network using proximal policy optimization.</li>
</ul>
<p>De et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-DeA.6571.pdf">Regression under human assistance</a> </p>
<ul>
<li>Motivation:<ul>
<li>Societies rely on human experts for import decisions</li>
<li>Timelineess and quality of the huan decisions are often compromised by large number of decisions, and shortage of human experts.</li>
<li>Let machines automate this procedure.</li>
<li>ML is still worse than humans in many cases.</li>
</ul>
</li>
<li>Goal: develop ML models that are optimized to operate under different automation levels.<ul>
<li>Take decisions for a given fraction of the instances, and defer to humans for the rest.</li>
<li>During training, optimize the machine for this scenario.</li>
</ul>
</li>
<li>Method: <ul>
<li>Ridge regression. See equation (1).</li>
<li>Ridge regression becomes a combinatorial problem.</li>
<li>This is NP hard</li>
<li>Express log l(S) as a difference of submodular functions. Use a heuristic iterative algorithm for submodular optimization.</li>
</ul>
</li>
<li>Evaluation: This greedy alg consistently outperforms the baselines across almost the entire range of automation levels on all datasets.</li>
</ul>
<p>Akula et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-AkulaA.3605.pdf">CoCoX: Generating conceptual and counterfactual explanations via fault-lines</a> </p>
<ul>
<li>Explain decisions made by a CNN</li>
<li>The features that humans zoon in on when they image an alternative to a model prediction: “fault-lines”.</li>
<li>Identify the “fault-line”, the minimal semantic-level features that need to be added / deleted from input image, in order to alter the classification category of image to another specified class.<ul>
<li>First select highly influential superpixels, and then apply K-means clustering with outlier removal, to form clusters (“explaining concept”).</li>
<li>Select the fault-line explaining concepts.</li>
</ul>
</li>
</ul>
<p>Bhardwaj et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-BhardwajA.6889.pdf">A human-AI loop approach for joint keyword discovery and expectation estimation in micropost event detection</a> </p>
<ul>
<li>Task: event detection on microposts. Given positive labels, unlabeled data. Goal: a binary classifier</li>
<li>Extract informative keyword and estimate their Expectation.</li>
</ul>
<h2 id="Cognitive-Modeling"><a href="#Cognitive-Modeling" class="headerlink" title="Cognitive Modeling"></a>Cognitive Modeling</h2><p>(Madison, 1400-1530)</p>
<p>Zhang et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhangW.178.pdf">Machine number sense: a dataset of visual arithmetic problems for abstract and relational reasoning</a> </p>
<ul>
<li>Motivation<ul>
<li>Human number sense: the cognitive process of numbers and mathematics. Human is able to perform induction of number symbols, is competent in problem solving, and have vision-based cognitive capacity.</li>
</ul>
</li>
<li>Dataset<ul>
<li>The MNS dataset: text number sense directly from pixel input. </li>
<li>Requires adaptive hierarchical representation based on context</li>
<li>Focus on reasoning and understanding, rather than recognition.</li>
<li>Investigate number sense from a cognitive perspective instead of a clinical perspective.</li>
</ul>
</li>
<li>Dataset generation<ul>
<li>Generate MNS by parsing and sampling an And-Or Graph (see figure 2)</li>
<li>Problem types: combination, composition, partition.</li>
<li>Layout component serves as problem context.</li>
</ul>
</li>
<li>Experiments and analysis<ul>
<li>Neural Network models </li>
<li>Symbolic search based models.</li>
</ul>
</li>
<li>Related Work:<ul>
<li>educational psychology, machine IQ and analogy</li>
</ul>
</li>
</ul>
<p>Ho et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-HoM.5623.pdf">The efficiency of human cognition reflects planned information processing</a> </p>
<ul>
<li>Imagine going on a trip</li>
<li>Partial planning via soft planning<ul>
<li>Control planning with state-specific inverse temperatures (a.g., attention) over represented states.</li>
<li>Partial planning + information theoretic costs</li>
</ul>
</li>
</ul>
<p>Rostami et al., <a target="_blank" rel="noopener" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-RostamiM.4481.pdf">Generative continual concept learning</a> </p>
<ul>
<li>Inspired by the Parallel Distributed Processing learning and Complementary Learning Systems theories, develop a computational model that is able to expand its previously learned concepts efficiently to new domains using a few labeled samples.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ziningzhu.me/2020/02/12/2020_02_AAAI/" data-id="ckljodjxd003z3k1y9kjfhhur" class="article-share-link">Share</a>
      
        <a href="http://ziningzhu.me/2020/02/12/2020_02_AAAI/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/conferences/" rel="tag">conferences</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/02/26/2020_02_pytorch_questions/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Pytorch Questions
        
      </div>
    </a>
  
  
    <a href="/2020/01/24/2020_01_deconfounding_age/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Deconfounding Age Impacts</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
      </div>
      <footer id="footer">
  
    <aside id="sidebar" class="outer">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/12/22/2020_12_books/">&bull; Cool Books in 2020</a>
          </li>
        
          <li>
            <a href="/2020/09/30/2020_09_RSTprobe/">&bull; Examining the rhetorical capacities of neural language models</a>
          </li>
        
          <li>
            <a href="/2020/09/21/2020_09_infoprobe/">&bull; An information theoretic view on selecting linguistic probes</a>
          </li>
        
          <li>
            <a href="/2020/07/10/2020_07_acl2020/">&bull; Trends in ACL 2020</a>
          </li>
        
          <li>
            <a href="/2020/04/12/2020_04_bayes_recap/">&bull; Tested Positive. Do I Have It?</a>
          </li>
        
          <li>
            <a href="/2020/02/26/2020_02_pytorch_questions/">&bull; Pytorch Questions</a>
          </li>
        
          <li>
            <a href="/2020/02/12/2020_02_AAAI/">&bull; AAAI2020</a>
          </li>
        
          <li>
            <a href="/2020/01/24/2020_01_deconfounding_age/">&bull; Deconfounding Age Impacts</a>
          </li>
        
          <li>
            <a href="/2019/12/31/2019_12_books/">&bull; Books I loved in 2019</a>
          </li>
        
          <li>
            <a href="/2019/12/09/2019_12_bash/">&bull; Familiarizing with Bash</a>
          </li>
        
          <li>
            <a href="/2019/08/15/2019_08_Kant/">&bull; When Pearl Meets Kant</a>
          </li>
        
          <li>
            <a href="/2019/06/09/2019_06_NAACL2019/">&bull; NAACL2019</a>
          </li>
        
          <li>
            <a href="/2019/04/15/2019_04_undergraduate_thesis/">&bull; Compositional Alignment of Word Embeddings</a>
          </li>
        
          <li>
            <a href="/2019/03/31/2019_03_distributed_systems/">&bull; Software Lessons from Distributed Systems</a>
          </li>
        
          <li>
            <a href="/2018/12/31/2018_12_books/">&bull; 4+4 Books I loved in 2018</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ExplainableAI/" style="font-size: 12.5px;">ExplainableAI</a> <a href="/tags/GAN/" style="font-size: 10px;">GAN</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/PGM/" style="font-size: 10px;">PGM</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/VAE/" style="font-size: 10px;">VAE</a> <a href="/tags/algorithms/" style="font-size: 12.5px;">algorithms</a> <a href="/tags/android/" style="font-size: 10px;">android</a> <a href="/tags/bash/" style="font-size: 10px;">bash</a> <a href="/tags/book-review/" style="font-size: 17.5px;">book-review</a> <a href="/tags/conferences/" style="font-size: 15px;">conferences</a> <a href="/tags/database/" style="font-size: 10px;">database</a> <a href="/tags/drone/" style="font-size: 10px;">drone</a> <a href="/tags/java/" style="font-size: 12.5px;">java</a> <a href="/tags/js/" style="font-size: 10px;">js</a> <a href="/tags/learning/" style="font-size: 12.5px;">learning</a> <a href="/tags/linguistics/" style="font-size: 10px;">linguistics</a> <a href="/tags/ml-basics/" style="font-size: 20px;">ml-basics</a> <a href="/tags/os/" style="font-size: 10px;">os</a> <a href="/tags/philosophy/" style="font-size: 15px;">philosophy</a> <a href="/tags/pytorch/" style="font-size: 12.5px;">pytorch</a> <a href="/tags/robotics/" style="font-size: 10px;">robotics</a> <a href="/tags/teamwork/" style="font-size: 10px;">teamwork</a> <a href="/tags/web/" style="font-size: 15px;">web</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Academia/">Academia</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Literature/">Literature</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Philosophy/">Philosophy</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Software/">Software</a></li></ul>
    </div>
  </div>


  
</aside>
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Zining Zhu
      <br>
      Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> with <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo-theme-landscape">Landscape</a>.
    </div>
  </div>

</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    
<script>
  var disqus_shortname = 'ziningzhu-me';
  
  var disqus_url = 'http://ziningzhu.me/2020/02/12/2020_02_AAAI/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" id=""></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>